# Questions

# Explain first the issue you are having, why aren't you able to produce a demo today?
"""
    I have a rough idea of what is needed from me in order to produce the demo, what I need to do is:

        - Separate each category into sentences and apply a label to them e.g. (INTRO, ALL, HIP)

        - Model sequence of labels and their textual context in clinical notes rather than considering each section
        independently.

        - The problem is formalised as a sequence labelling tasks:
            - Given a clinical note with n sections x = (X1, ..., Xn),
            - Determine the optimal sequence of section labels S = (S1, ..., Sn) among all possible section sequences.

        - Token: text separated by white space.
        - Text Span: consists of tokens which extend between two section labels.

        A clinical note is represented as a sequence of text spans, each presumed to convey information about a
        specific section.

        Train HMM with 15 states, with eac states corresponding in intuition to a distinct section label.

        For a given text span, the observations for eac state are modeled according to a bigram language model specific
        to each section type.
"""

"""
    The particular article I was reading mentioned other articles that operated at the sentence level,
        - Lin and colleagues annotated sentences with labels through a generative model? Features were bigram language 
        model for each of the sections. The language models were smoothed with Kneser-Ney discounting and Katz backoff
        
        Kneser-key discounting: method used to calculate the probability of n-grams in a document based on their 
        histories.
"""

"""
    Generative Model: can generate new data instances. E.g. A generate model could generate new photos of animals that
    look like real animals.
    Discriminative Model: discriminate between different kinds of data instances. E.g. A discriminative model could tell
    a dog from a cat.
"""